import os
import sys

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))

import requests
from backend.app.gemini_validation import validate_similarity_with_gemini

from backend.app.text_similarity import create_faiss_index
from backend.app.text_similarity import calculate_similarity

from backend.app.text_similarity import calculate_percentage_similarity

issue_title = os.getenv("ISSUE_TITLE")
issue_number = os.getenv("ISSUE_NUMBER")
repo = os.getenv("REPO")
token = os.getenv("GH_TOKEN")

headers = {
    "Authorization": f"token {token}",
    "Accept": "application/vnd.github+json"
}
# Notify the user that the bot is running
comment_url = f"https://api.github.com/repos/{repo}/issues/{issue_number}/comments"
"""comment_payload = {"body": "ğŸ” Dupligit Bot is checking for similar issues. Please wait..."}
resp = requests.post(comment_url, headers=headers, json=comment_payload)

# DEBUG OUTPUT
print("ğŸ§ª DEBUG: Comment POST status:", resp.status_code)
print("ğŸ§ª DEBUG: Comment POST response:", resp.text)"""

# Step 1: Fetch all other issue titles
r = requests.get(f"https://api.github.com/repos/{repo}/issues", headers=headers)
issues = r.json()
filtered_issues = [(i["title"], i["number"]) for i in issues if str(i["number"]) != issue_number]
unique_titles = list(dict.fromkeys([t[0] for t in filtered_issues]))
titles = unique_titles

if not titles:
    requests.post(comment_url, headers=headers, json={"body": "â„¹ï¸ No other issues found to compare."})
    exit(0)

# Step 2: Create FAISS index and calculate similarity
faiss_index, model = create_faiss_index(titles)
results = calculate_similarity(faiss_index, model, titles, issue_title)
scores = [score for _, score in results]

percentage_similarities = calculate_percentage_similarity(scores)
# ğŸ” Prepare Gemini input
current_issue = next((i for i in issues if str(i["number"]) == issue_number), {})
issue_body = current_issue.get("body", "")

top_n = 3
top_results = results[:top_n]
top_scores = percentage_similarities[:top_n]

similar_issues = []
for (title, _), score in zip(top_results, top_scores):
    matched = next((i for i in issues if i["title"] == title), {})
    similar_issues.append({
        "title": matched.get("title", ""),
        "body": matched.get("body", ""),
        "score": score
    })

gemini_response = validate_similarity_with_gemini(issue_title, issue_body, similar_issues)


base_comment = (
    f"ğŸ” **Dupligit Bot Report**\n\n"
    f"ğŸ“ Incoming Issue: _{issue_title}_\n\n"
)

if percentage_similarities[0] > 70.0:
    base_comment += (
        "ğŸ” **Potential Duplicate Issues Found**\n\n"
        "We've detected similar issues to this one:\n\n"
        "| Issue # | Title | Similarity |\n"
        "|---------|-------|------------|\n"
    )

    for i, (title, _) in enumerate(results[:5]):
        percentage = percentage_similarities[i]
        if percentage < 70.0:
            continue

        issue_index = next((num for t, num in filtered_issues if t == title), None)
        if issue_index is None:
            continue
        title_link = f"https://github.com/{repo}/issues/{issue_index}"
        safe_title = title.replace("|", "ï½œ")  # escape markdown pipe
        base_comment += f"| [#{issue_index}]({title_link}) | {safe_title} | {percentage:.0f}% |\n"

    base_comment += (
        "\nğŸ“Œ Label `needs-duplicate-review` has been added.\n"
        "\nğŸ”§ Maintainers can confirm by commenting:\n"
        "```bash\n/mark-duplicate #<issue_number>\n```"
    )

    # Step 4: Add label
    label_url = f"https://api.github.com/repos/{repo}/issues/{issue_number}/labels"
    requests.post(label_url, headers=headers, json={"labels": ["needs-duplicate-review"]})

else:
    base_comment += "âœ… No strong duplicate candidates found. You may proceed."

base_comment += f"\n\nğŸ§  **Gemini Review**\n```\n{gemini_response}\n```"

# Step 5: Post final comment
requests.post(comment_url, headers=headers, json={"body": base_comment})